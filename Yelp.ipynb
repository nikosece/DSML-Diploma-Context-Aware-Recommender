{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords  \n",
    "from nltk.tokenize import word_tokenize \n",
    "import sys\n",
    "import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN ONLY ONCE ###\n",
    "\n",
    "# business_json_path = 'yelp_academic_dataset_business.json'\n",
    "# df_b = pd.read_json(business_json_path, lines=True)\n",
    "# # 1 = open, 0 = closed\n",
    "# df_b = df_b[df_b['is_open']==1]\n",
    "# drop_columns = ['hours','is_open','review_count','address']\n",
    "# df_b = df_b.drop(drop_columns, axis=1)\n",
    "# df_b.to_csv('bussines.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN ONLY ONCE ###\n",
    "\n",
    "\n",
    "# review_json_path = 'yelp_academic_dataset_review.json'\n",
    "# size = 1000000\n",
    "# review = pd.read_json(review_json_path, lines=True,\n",
    "#                       dtype={'review_id':str,'user_id':str,\n",
    "#                              'business_id':str,'stars':int,\n",
    "#                              'date':str,'text':str,'useful':int,\n",
    "#                              'funny':int,'cool':int},\n",
    "#                       chunksize=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN ONLY ONCE ###\n",
    "\n",
    "\n",
    "# There are multiple chunks to be read\n",
    "# chunk_list = []\n",
    "# for chunk_review in review:\n",
    "#     # Drop columns that aren't needed\n",
    "#     chunk_review = chunk_review.drop(['review_id','useful','funny','cool'], axis=1)\n",
    "#     # Renaming column name to avoid conflict with business overall star rating\n",
    "#     chunk_review = chunk_review.rename(columns={'stars': 'review_stars'})\n",
    "#     # Inner merge with edited business file so only reviews related to the business remain\n",
    "#     chunk_merged = pd.merge(df_b, chunk_review, on='business_id', how='inner')\n",
    "#     # Show feedback on progress\n",
    "#     print(f\"{chunk_merged.shape[0]} out of {size:,} related reviews\")\n",
    "#     chunk_list.append(chunk_merged)\n",
    "# # # After trimming down the review file, concatenate all relevant data back to one dataframe\n",
    "# df = pd.concat(chunk_list, ignore_index=True, join='outer', axis=0)\n",
    "#df.to_csv('reviews.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### KEEP ONLY RESTARUNTS ###\n",
    "business_R = df_b[df_b['categories'].str.contains('Restaurants',case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read bussines.csv ###\n",
    "### using df_b.loc[id of bussines] to find it ##\n",
    "\n",
    "df_b = pd.read_csv('bussines.csv',dtype={'name':str,\n",
    "                              'city':str, 'state':str, 'postal_code':str,\n",
    "                              'latitude':float, 'longitude':float,             \n",
    "                              'business_id':str,'stars':float,\n",
    "                               'attributes':str,'categories':str},index_col='business_id')\n",
    "#df_b.head()\n",
    "df_explode = df_b.assign(categories = df_b.categories.str.split(', ')).explode('categories')\n",
    "df_explode.categories.value_counts()\n",
    "#df_b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read reviews.csv with business id ###\n",
    "### This csv contains only reviews for open bussines, as they were filtered at the begining ###\n",
    "### using df.loc[id of user] to find all of his reviews ##\n",
    "\n",
    "\n",
    "df_r = pd.read_csv(\"reviews_cleared.csv\",dtype={'user_id':str,            \n",
    "                              'business_id':str,'review_stars':np.int8,'text':str},parse_dates=[\"date\"],index_col='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read users.csv ###\n",
    "### This csv contains only reviews for open bussines, as they were filtered at the begining ###\n",
    "### using df.loc[id of user] to find all of his friends ##\n",
    "df_u = pd.read_csv(\"users.csv\",dtype={'friends':str},index_col='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read chekin.csv ###\n",
    "### This csv contains only chekins for open bussines, as they were filtered at the begining ###\n",
    "### using df.loc[id of bussines] to find all of his friends ##\n",
    "df_c = pd.read_csv(\"checkin.csv\",parse_dates=[\"dates\"],index_col='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read tips.csv ###\n",
    "### This csv contains only chekins for open bussines, as they were filtered at the begining ###\n",
    "### using df.loc[id of bussines] to find all of his friends ##\n",
    "df_t = pd.read_csv(\"tips.csv\",dtype={'user_id':str,'text':str}, index_col='business_id',parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f9NumwFMBDn751xgFiRbNA</th>\n",
       "      <td>The Range At Lake Norman</td>\n",
       "      <td>Cornelius</td>\n",
       "      <td>NC</td>\n",
       "      <td>28031</td>\n",
       "      <td>35.462724</td>\n",
       "      <td>-80.852612</td>\n",
       "      <td>3.5</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': 'True', 'BikePa...</td>\n",
       "      <td>Active Life, Gun/Rifle Ranges, Guns &amp; Ammo, Sh...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yzvjg0SayhoZgCljUJRF9Q</th>\n",
       "      <td>Carlos Santo, NMD</td>\n",
       "      <td>Scottsdale</td>\n",
       "      <td>AZ</td>\n",
       "      <td>85258</td>\n",
       "      <td>33.569404</td>\n",
       "      <td>-111.890264</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'GoodForKids': 'True', 'ByAppointmentOnly': '...</td>\n",
       "      <td>Health &amp; Medical, Fitness &amp; Instruction, Yoga,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XNoUzKckATkOD1hP6vghZg</th>\n",
       "      <td>Felinus</td>\n",
       "      <td>Montreal</td>\n",
       "      <td>QC</td>\n",
       "      <td>H4C 1P4</td>\n",
       "      <td>45.479984</td>\n",
       "      <td>-73.580070</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pets, Pet Services, Pet Groomers</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51M2Kk903DFYI6gnB5I6SQ</th>\n",
       "      <td>USE MY GUY SERVICES LLC</td>\n",
       "      <td>Mesa</td>\n",
       "      <td>AZ</td>\n",
       "      <td>85205</td>\n",
       "      <td>33.428065</td>\n",
       "      <td>-111.726648</td>\n",
       "      <td>4.5</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': 'True', 'ByAppo...</td>\n",
       "      <td>Home Services, Plumbing, Electricians, Handyma...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cKyLV5oWZJ2NudWgqs8VZw</th>\n",
       "      <td>Oasis Auto Center - Gilbert</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>AZ</td>\n",
       "      <td>85233</td>\n",
       "      <td>33.350399</td>\n",
       "      <td>-111.827142</td>\n",
       "      <td>4.5</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': 'True'}</td>\n",
       "      <td>Auto Repair, Automotive, Oil Change Stations, ...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               name        city state  \\\n",
       "business_id                                                             \n",
       "f9NumwFMBDn751xgFiRbNA     The Range At Lake Norman   Cornelius    NC   \n",
       "Yzvjg0SayhoZgCljUJRF9Q            Carlos Santo, NMD  Scottsdale    AZ   \n",
       "XNoUzKckATkOD1hP6vghZg                      Felinus    Montreal    QC   \n",
       "51M2Kk903DFYI6gnB5I6SQ      USE MY GUY SERVICES LLC        Mesa    AZ   \n",
       "cKyLV5oWZJ2NudWgqs8VZw  Oasis Auto Center - Gilbert     Gilbert    AZ   \n",
       "\n",
       "                       postal_code   latitude   longitude  stars  \\\n",
       "business_id                                                        \n",
       "f9NumwFMBDn751xgFiRbNA       28031  35.462724  -80.852612    3.5   \n",
       "Yzvjg0SayhoZgCljUJRF9Q       85258  33.569404 -111.890264    5.0   \n",
       "XNoUzKckATkOD1hP6vghZg     H4C 1P4  45.479984  -73.580070    5.0   \n",
       "51M2Kk903DFYI6gnB5I6SQ       85205  33.428065 -111.726648    4.5   \n",
       "cKyLV5oWZJ2NudWgqs8VZw       85233  33.350399 -111.827142    4.5   \n",
       "\n",
       "                                                               attributes  \\\n",
       "business_id                                                                 \n",
       "f9NumwFMBDn751xgFiRbNA  {'BusinessAcceptsCreditCards': 'True', 'BikePa...   \n",
       "Yzvjg0SayhoZgCljUJRF9Q  {'GoodForKids': 'True', 'ByAppointmentOnly': '...   \n",
       "XNoUzKckATkOD1hP6vghZg                                                NaN   \n",
       "51M2Kk903DFYI6gnB5I6SQ  {'BusinessAcceptsCreditCards': 'True', 'ByAppo...   \n",
       "cKyLV5oWZJ2NudWgqs8VZw             {'BusinessAcceptsCreditCards': 'True'}   \n",
       "\n",
       "                                                               categories  \\\n",
       "business_id                                                                 \n",
       "f9NumwFMBDn751xgFiRbNA  Active Life, Gun/Rifle Ranges, Guns & Ammo, Sh...   \n",
       "Yzvjg0SayhoZgCljUJRF9Q  Health & Medical, Fitness & Instruction, Yoga,...   \n",
       "XNoUzKckATkOD1hP6vghZg                   Pets, Pet Services, Pet Groomers   \n",
       "51M2Kk903DFYI6gnB5I6SQ  Home Services, Plumbing, Electricians, Handyma...   \n",
       "cKyLV5oWZJ2NudWgqs8VZw  Auto Repair, Automotive, Oil Change Stations, ...   \n",
       "\n",
       "                        review_count  \n",
       "business_id                           \n",
       "f9NumwFMBDn751xgFiRbNA            36  \n",
       "Yzvjg0SayhoZgCljUJRF9Q             4  \n",
       "XNoUzKckATkOD1hP6vghZg             5  \n",
       "51M2Kk903DFYI6gnB5I6SQ            26  \n",
       "cKyLV5oWZJ2NudWgqs8VZw            38  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>review_stars</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>xDtS2iKsJuVUVzB2YhfPsg</th>\n",
       "      <td>f9NumwFMBDn751xgFiRbNA</td>\n",
       "      <td>4</td>\n",
       "      <td>driving half-hour get gun range getting old . ...</td>\n",
       "      <td>2012-06-26 00:48:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46HhzhpBfTdTSB5ceTx_Og</th>\n",
       "      <td>f9NumwFMBDn751xgFiRbNA</td>\n",
       "      <td>4</td>\n",
       "      <td>dad came area visit , wife mom went shopping d...</td>\n",
       "      <td>2012-05-29 23:44:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vBxT4_bjFrbZEarWz6vsCQ</th>\n",
       "      <td>f9NumwFMBDn751xgFiRbNA</td>\n",
       "      <td>4</td>\n",
       "      <td>first time last time . 'm punk ! ! ! 22 9 mag ...</td>\n",
       "      <td>2017-06-18 00:24:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qiz4Ri_cMSsoH3ccN19eAw</th>\n",
       "      <td>f9NumwFMBDn751xgFiRbNA</td>\n",
       "      <td>5</td>\n",
       "      <td>besides great range , cheap . would cost cool ...</td>\n",
       "      <td>2016-02-14 02:28:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0awwOxKGZVDt52vxkEX-eA</th>\n",
       "      <td>f9NumwFMBDn751xgFiRbNA</td>\n",
       "      <td>1</td>\n",
       "      <td>place nice look , would n't really want stick ...</td>\n",
       "      <td>2014-05-28 20:00:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   business_id  review_stars  \\\n",
       "user_id                                                        \n",
       "xDtS2iKsJuVUVzB2YhfPsg  f9NumwFMBDn751xgFiRbNA             4   \n",
       "46HhzhpBfTdTSB5ceTx_Og  f9NumwFMBDn751xgFiRbNA             4   \n",
       "vBxT4_bjFrbZEarWz6vsCQ  f9NumwFMBDn751xgFiRbNA             4   \n",
       "qiz4Ri_cMSsoH3ccN19eAw  f9NumwFMBDn751xgFiRbNA             5   \n",
       "0awwOxKGZVDt52vxkEX-eA  f9NumwFMBDn751xgFiRbNA             1   \n",
       "\n",
       "                                                                     text  \\\n",
       "user_id                                                                     \n",
       "xDtS2iKsJuVUVzB2YhfPsg  driving half-hour get gun range getting old . ...   \n",
       "46HhzhpBfTdTSB5ceTx_Og  dad came area visit , wife mom went shopping d...   \n",
       "vBxT4_bjFrbZEarWz6vsCQ  first time last time . 'm punk ! ! ! 22 9 mag ...   \n",
       "qiz4Ri_cMSsoH3ccN19eAw  besides great range , cheap . would cost cool ...   \n",
       "0awwOxKGZVDt52vxkEX-eA  place nice look , would n't really want stick ...   \n",
       "\n",
       "                                      date  \n",
       "user_id                                     \n",
       "xDtS2iKsJuVUVzB2YhfPsg 2012-06-26 00:48:30  \n",
       "46HhzhpBfTdTSB5ceTx_Og 2012-05-29 23:44:04  \n",
       "vBxT4_bjFrbZEarWz6vsCQ 2017-06-18 00:24:54  \n",
       "qiz4Ri_cMSsoH3ccN19eAw 2016-02-14 02:28:57  \n",
       "0awwOxKGZVDt52vxkEX-eA 2014-05-28 20:00:46  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>dates</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>--1UhMGODdWsrMastO9DZw</th>\n",
       "      <td>7</td>\n",
       "      <td>[datetime.datetime(2016, 4, 26, 19, 49, 16), d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--6MefnULPED_I942VcFNA</th>\n",
       "      <td>189</td>\n",
       "      <td>[datetime.datetime(2011, 6, 4, 18, 22, 23), da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--7zmmkVg-IMGaXbuVd0SQ</th>\n",
       "      <td>193</td>\n",
       "      <td>[datetime.datetime(2014, 12, 29, 19, 25, 50), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--8LPVSo5i0Oo61X01sV9A</th>\n",
       "      <td>1</td>\n",
       "      <td>[datetime.datetime(2016, 7, 8, 16, 43, 30)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--9QQLMTbFzLJ_oT-ON3Xw</th>\n",
       "      <td>38</td>\n",
       "      <td>[datetime.datetime(2010, 6, 26, 17, 39, 7), da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        total  \\\n",
       "business_id                     \n",
       "--1UhMGODdWsrMastO9DZw      7   \n",
       "--6MefnULPED_I942VcFNA    189   \n",
       "--7zmmkVg-IMGaXbuVd0SQ    193   \n",
       "--8LPVSo5i0Oo61X01sV9A      1   \n",
       "--9QQLMTbFzLJ_oT-ON3Xw     38   \n",
       "\n",
       "                                                                    dates  \n",
       "business_id                                                                \n",
       "--1UhMGODdWsrMastO9DZw  [datetime.datetime(2016, 4, 26, 19, 49, 16), d...  \n",
       "--6MefnULPED_I942VcFNA  [datetime.datetime(2011, 6, 4, 18, 22, 23), da...  \n",
       "--7zmmkVg-IMGaXbuVd0SQ  [datetime.datetime(2014, 12, 29, 19, 25, 50), ...  \n",
       "--8LPVSo5i0Oo61X01sV9A        [datetime.datetime(2016, 7, 8, 16, 43, 30)]  \n",
       "--9QQLMTbFzLJ_oT-ON3Xw  [datetime.datetime(2010, 6, 26, 17, 39, 7), da...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UYX5zL_Xj9WEc_Wp-FrqHw</th>\n",
       "      <td>hf27xTME3EiCp6NL6VtWZQ</td>\n",
       "      <td>Here for a quick mtg</td>\n",
       "      <td>2013-11-26 18:20:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UYX5zL_Xj9WEc_Wp-FrqHw</th>\n",
       "      <td>Wi0VgIrbb8vqU6weyVw6tg</td>\n",
       "      <td>Surprised by the inventory! Was looking for a ...</td>\n",
       "      <td>2011-07-25 02:03:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UYX5zL_Xj9WEc_Wp-FrqHw</th>\n",
       "      <td>5J4uykvpVCZ3pwceIKf45g</td>\n",
       "      <td>Thomas train table is a lot of fun!</td>\n",
       "      <td>2012-04-15 16:15:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UYX5zL_Xj9WEc_Wp-FrqHw</th>\n",
       "      <td>dWkaK0k-5WSY4BJny1BtHw</td>\n",
       "      <td>Scanning books I want for Lydia and adding the...</td>\n",
       "      <td>2011-10-13 21:35:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UYX5zL_Xj9WEc_Wp-FrqHw</th>\n",
       "      <td>8HXpvdxGR_yBQuA_T23Cxw</td>\n",
       "      <td>Mockingjay!!</td>\n",
       "      <td>2012-04-11 03:33:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       user_id  \\\n",
       "business_id                                      \n",
       "UYX5zL_Xj9WEc_Wp-FrqHw  hf27xTME3EiCp6NL6VtWZQ   \n",
       "UYX5zL_Xj9WEc_Wp-FrqHw  Wi0VgIrbb8vqU6weyVw6tg   \n",
       "UYX5zL_Xj9WEc_Wp-FrqHw  5J4uykvpVCZ3pwceIKf45g   \n",
       "UYX5zL_Xj9WEc_Wp-FrqHw  dWkaK0k-5WSY4BJny1BtHw   \n",
       "UYX5zL_Xj9WEc_Wp-FrqHw  8HXpvdxGR_yBQuA_T23Cxw   \n",
       "\n",
       "                                                                     text  \\\n",
       "business_id                                                                 \n",
       "UYX5zL_Xj9WEc_Wp-FrqHw                               Here for a quick mtg   \n",
       "UYX5zL_Xj9WEc_Wp-FrqHw  Surprised by the inventory! Was looking for a ...   \n",
       "UYX5zL_Xj9WEc_Wp-FrqHw                Thomas train table is a lot of fun!   \n",
       "UYX5zL_Xj9WEc_Wp-FrqHw  Scanning books I want for Lydia and adding the...   \n",
       "UYX5zL_Xj9WEc_Wp-FrqHw                                       Mockingjay!!   \n",
       "\n",
       "                                      date  \n",
       "business_id                                 \n",
       "UYX5zL_Xj9WEc_Wp-FrqHw 2013-11-26 18:20:08  \n",
       "UYX5zL_Xj9WEc_Wp-FrqHw 2011-07-25 02:03:06  \n",
       "UYX5zL_Xj9WEc_Wp-FrqHw 2012-04-15 16:15:12  \n",
       "UYX5zL_Xj9WEc_Wp-FrqHw 2011-10-13 21:35:53  \n",
       "UYX5zL_Xj9WEc_Wp-FrqHw 2012-04-11 03:33:53  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>friends</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ntlvfPzc8eglqvk92iDIAw</th>\n",
       "      <td>oeMvJh94PiGQnx_6GlndPQ, wm1z1PaJKvHgSDRKfwhfDg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOBRPlBHa3WPHFB5qYDlVg</th>\n",
       "      <td>ly7EnE8leJmyqyePVYFlug, pRlR63iDytsnnniPb3AOug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zZUnPeh2hEp0WydbAZEOOg</th>\n",
       "      <td>Uwlk0txjQBPw_JhHsQnyeg, Ybxr1tSCkv3lYA0I1qmnPQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QaELAmRcDc5TfJEylaaP8g</th>\n",
       "      <td>iog3Nyg1i4jeumiTVG_BSA, M92xWY2Vr9w0xoH8bPplfQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xvu8G900tezTzbbfqmTKvA</th>\n",
       "      <td>3W3ZMSthojCUirKEqAwGNw, eTIbuu23j9tOgmIa9POyLQ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  friends\n",
       "user_id                                                                  \n",
       "ntlvfPzc8eglqvk92iDIAw  oeMvJh94PiGQnx_6GlndPQ, wm1z1PaJKvHgSDRKfwhfDg...\n",
       "FOBRPlBHa3WPHFB5qYDlVg  ly7EnE8leJmyqyePVYFlug, pRlR63iDytsnnniPb3AOug...\n",
       "zZUnPeh2hEp0WydbAZEOOg  Uwlk0txjQBPw_JhHsQnyeg, Ybxr1tSCkv3lYA0I1qmnPQ...\n",
       "QaELAmRcDc5TfJEylaaP8g  iog3Nyg1i4jeumiTVG_BSA, M92xWY2Vr9w0xoH8bPplfQ...\n",
       "xvu8G900tezTzbbfqmTKvA  3W3ZMSthojCUirKEqAwGNw, eTIbuu23j9tOgmIa9POyLQ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_u.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN ONLY ONCE ###\n",
    "\n",
    "#######pre_processing.py########\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "# def remove_stop_words(sentence):\n",
    "#     if type(sentence)==str:\n",
    "#         sentence = sentence.lower()\n",
    "#         word_tokens = word_tokenize(sentence)\n",
    "#         filtered_sentence = [w for w in word_tokens if not w in stop_words]   \n",
    "#         merged_sentence = \" \".join(filtered_sentence)\n",
    "#         return merged_sentence\n",
    "#     else:\n",
    "#         return np.nan\n",
    "\n",
    "# df_r['text'] = df_r.apply(lambda row : remove_stop_words(row['text']), axis = 1) \n",
    "# updated_dataset = df_r.to_csv('reviews_cleared.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considering to keep the text of the review so that i can find similar reviews with cosine similarity\n",
    "### It maybe better to filter data first with category so to make choices a lot of fewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Deal only with data that belong to a specific category ####\n",
    "\n",
    "def  categorize(top=10,category=False):\n",
    "    df_explode = df_b.assign(categories = df_b.categories.str.split(', ')).explode('categories')[\"categories\"]\n",
    "    print(\"There are the top {} categories\".format(top))\n",
    "    print(df_explode.value_counts(normalize=True).nlargest(top))\n",
    "    if category:\n",
    "        a = input(\"Please specify category string\")\n",
    "        print(\"{} selected\".format(a))\n",
    "        df_b_specific = df_b[df_b['categories'].str.contains(a, na=False)]\n",
    "    else:\n",
    "        for val, cnt in df_explode.value_counts(normalize=True).nlargest(1).iteritems():\n",
    "            print(\"{} selected\".format(val))\n",
    "            df_b_specific = df_b[df_b['categories'].str.contains(val, na=False)]\n",
    "    df_r_specific = df_r[df_r['business_id'].isin(df_b_specific.index)]\n",
    "    return df_b_specific,df_r_specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are the top 10 categories\n",
      "Restaurants                  0.061515\n",
      "Shopping                     0.039849\n",
      "Food                         0.034761\n",
      "Home Services                0.028897\n",
      "Health & Medical             0.024662\n",
      "Beauty & Spas                0.024196\n",
      "Local Services               0.020035\n",
      "Automotive                   0.018398\n",
      "Nightlife                    0.013737\n",
      "Event Planning & Services    0.013292\n",
      "Name: categories, dtype: float64\n",
      "Restaurants selected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4222976, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bus,b = categorize()\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = calculate_cosine(b,\"greek greece feta souvlaki gyros tzatziki athens \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_scores_1 = sorted(scores.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in  list(scores.keys()):\n",
    "    star = RatingExtractor.get_rating_weight(bus.loc[[key]].stars.values[0])\n",
    "    scores[key] = calculate_final_score(a[key],star)\n",
    "sorted_scores_2 = sorted(scores.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('w12EoDqaRXzN9KsouzRMyw', 0.008123911416994659)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_final_score(cs, r):\n",
    "    amount = (cs / 100) * r\n",
    "    return cs + amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create cosine similarity for user reviews\n",
    "## return only bussines_ids which reviews have cosine_similarity for specific keywords possitive\n",
    "###############################################################################################\n",
    "###                                  EXAMPLE                                                ###\n",
    "### sorted_scores = calculate_cosine(b,\"greek greece feta souvlaki gyros tzatziki athens \") ###\n",
    "##############################################################################################\n",
    "\n",
    "def calculate_cosine(b,sec):\n",
    "    score_dict = {}\n",
    "    for index, row in b.iterrows():\n",
    "        try:\n",
    "            a = CosineSimilarity.cosine_similarity_of(row['text'], sec)\n",
    "            if a>0:\n",
    "                if row['business_id'] not in score_dict:\n",
    "                    score_dict[row['business_id']] = a\n",
    "                else:\n",
    "                    score_dict[row['business_id']] = (score_dict[row['business_id']]+a)/2.0\n",
    "        except:\n",
    "        ### There is one text with nan that causes exception ###    \n",
    "            continue\n",
    "    #sorted_scores = sorted(score_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Cosine Similarity #######\n",
    "import re, math\n",
    "from collections import Counter\n",
    "\n",
    "class CosineSimilarity:\n",
    "    def __init__(self):\n",
    "        print(\"Cosine Similarity initialized\")\n",
    "\n",
    "    @staticmethod\n",
    "    def cosine_similarity_of(text1, text2):\n",
    "        #get words first\n",
    "        first = re.compile(r\"[\\w']+\").findall(text1)\n",
    "        second = re.compile(r\"[\\w']+\").findall(text2)\n",
    "\n",
    "        #get dictionary with each word and count.\n",
    "        vector1 = Counter(first)\n",
    "        vector2 = Counter(second)\n",
    "\n",
    "        #convert vectors to set to find common words as intersection\n",
    "        common = set(vector1.keys()).intersection(set(vector2.keys()))\n",
    "\n",
    "        dot_product = 0.0\n",
    "\n",
    "        for i in common:\n",
    "            #get amount of each common word for both vectors and multiply them then add them together.\n",
    "            dot_product += vector1[i] * vector2[i]\n",
    "\n",
    "        squared_sum_vector1 = 0.0\n",
    "        squared_sum_vector2 = 0.0\n",
    "\n",
    "        #get squared sum values of word counts from each vector.\n",
    "        for i in vector1.keys():\n",
    "            squared_sum_vector1 += vector1[i]**2\n",
    "\n",
    "        for i in vector2.keys():\n",
    "            squared_sum_vector2 += vector2[i]**2\n",
    "\n",
    "        #calculate magnitude with squared sums.\n",
    "        magnitude = math.sqrt(squared_sum_vector1) * math.sqrt(squared_sum_vector2)\n",
    "\n",
    "        if not magnitude:\n",
    "           return 0.0\n",
    "        else:\n",
    "           return float(dot_product) / magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import e\n",
    "class RatingExtractor:\n",
    "    def __init__(self):\n",
    "        print(\"rating initialized\")\n",
    "\n",
    "    #Returns value between -q and q. for rating input between 0 and 10.\n",
    "    #Parameters:\n",
    "        #rating: indicates the rating for the destination\n",
    "        #q: indicates the percentage of rating for general score. (default is 10.)\n",
    "    @staticmethod\n",
    "    def get_rating_weight(rating, q=10):\n",
    "        if rating > 5 or rating < 0:\n",
    "            return None\n",
    "        else:\n",
    "            m = (2*q) / 5 #10 because rating varies between 0 and 10\n",
    "            b = -q\n",
    "            return (m*rating) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Recommender Engine #####\n",
    "\n",
    "import pandas as pd\n",
    "from cosine_similarity import CosineSimilarity\n",
    "import operator\n",
    "import json\n",
    "\n",
    "class RecommenderEngine:\n",
    "    def __init__(self):\n",
    "        print(\"engine initialized\")\n",
    "        \n",
    "    def calculate_final_score(cs, r):\n",
    "        amount = (cs / 100) * r\n",
    "        return cs + amount\n",
    "\n",
    "    def get_recommendations(keywords):\n",
    "\n",
    "        df = pd.read_csv('reviews_cleared.csv')\n",
    "\n",
    "        score_dict = {}\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            score_dict[index] = CosineSimilarity.cosine_similarity_of(row['text'], keywords)\n",
    "\n",
    "        #sort cities by score and index.\n",
    "        sorted_scores = sorted(score_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "        counter = 0\n",
    "\n",
    "        #create an empty results data frame.\n",
    "        resultDF = pd.DataFrame(columns=('business_id', 'score'))\n",
    "\n",
    "        #get highest scored 5 cities.\n",
    "        for i in sorted_scores:\n",
    "            #print index and score of the city.\n",
    "            #print(i[0], i[1])\n",
    "            resultDF = resultDF.append({'business_id': df.iloc[i[0]]['business_id'], 'score': i[1]}, ignore_index=True)\n",
    "            counter += 1\n",
    "\n",
    "            if counter>4:\n",
    "                break\n",
    "\n",
    "        #convert DF to json.\n",
    "        json_result = json.dumps(resultDF.to_dict('records'))\n",
    "        return json_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-8fbce41c09bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mtop_5_cultural_cities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_recommendations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mculture_keywords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[0mcity_names_for_cultural\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_top_5_city_names_out_of_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop_5_cultural_cities\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcity_names_for_cultural\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-8fbce41c09bc>\u001b[0m in \u001b[0;36mget_recommendations\u001b[1;34m(keywords)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_recommendations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRecommenderEngine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_recommendations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-5b09b017f147>\u001b[0m in \u001b[0;36mget_recommendations\u001b[1;34m(keywords)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_recommendations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'reviews_cleared.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mscore_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1184\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1186\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2143\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2144\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2145\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2146\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2147\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu2\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m     \"\"\"\n\u001b[0;32m    532\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Request ###\n",
    "\n",
    "#from recommender_engine import RecommenderEngine\n",
    "import json\n",
    "\n",
    "culture_keywords = \"history historical art architecture city culture\"\n",
    "beach_n_sun_keywords = \"beach beaches park nature holiday sea seaside sand sunshine sun sunny\"\n",
    "nightlife_keywords = \"nightclub nightclubs nightlife bar bars pub pubs party beer\"\n",
    "\n",
    "def get_recommendations(keywords):\n",
    "    result = RecommenderEngine.get_recommendations(keywords)\n",
    "    return result\n",
    "\n",
    "def get_top_5_city_names_out_of_json(json_string):\n",
    "    list = json.loads(json_string)\n",
    "    result = []\n",
    "    max = len(list)\n",
    "    i = 0\n",
    "    while i < max:\n",
    "        result.append((list[i]['id'], list[i]['score']))\n",
    "        i += 1\n",
    "\n",
    "    return result\n",
    "\n",
    "top_5_cultural_cities = get_recommendations(culture_keywords)\n",
    "city_names_for_cultural = get_top_5_city_names_out_of_json(top_5_cultural_cities)\n",
    "print(city_names_for_cultural)\n",
    "print(\"#################\")\n",
    "top_5_summer_cities = get_recommendations(beach_n_sun_keywords)\n",
    "city_names_for_summer = get_top_5_city_names_out_of_json(top_5_summer_cities)\n",
    "print(city_names_for_summer)\n",
    "print(\"#################\")\n",
    "top_5_party_cities = get_recommendations(nightlife_keywords)\n",
    "city_names_for_party = get_top_5_city_names_out_of_json(top_5_party_cities)\n",
    "print(city_names_for_party)\n",
    "print(\"#################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c['test'] = df_c.apply(lambda row : to_date(row['date']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_date(str_date):\n",
    "    result = list()\n",
    "    str_result = str_date.split(\",\")\n",
    "    for i in str_result:\n",
    "        if i[0] ==\" \":\n",
    "            result.append(datetime.datetime.strptime(i[1:], '%Y-%m-%d %H:%M:%S'))\n",
    "        else:\n",
    "            result.append(datetime.datetime.strptime(i, '%Y-%m-%d %H:%M:%S'))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split categories names and count each category\n",
    "\n",
    "df_explode = df_b.assign(categories = df_b.categories.str.split(', ')).explode('categories')[\"'categories'\"]\n",
    "#df_explode.categories.value_counts()\n",
    "## keep only Restarants category\n",
    "df_Restaurants = df_explode[df_explode[\"categories\"]==\"Restaurants\"]\n",
    "\n",
    "## keep only the reviews containig business_id in specific categories\n",
    "df_r = df_r[df_r['business_id'].isin(df_Restaurants.index)]\n",
    "\n",
    "import datetime\n",
    "\n",
    "### Keep only scecific dates ###\n",
    "date_time_str = '2019-01-01'\n",
    "date_time_obj = datetime.datetime.strptime(date_time_str, '%Y-%m-%d')\n",
    "df_r = df_r[df_r['date']>= date_time_obj]\n",
    "df_r = df_r[df_r['review_stars']>= 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words and use TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english',max_features=1000)\n",
    "# Construct TF-IDF matrix\n",
    "tfidf_matrix = tfidf.fit_transform(df_r[~(df_r['text'].isnull())]['text'])\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "# Get corresponding indices of the movies\n",
    "#indices = pd.Series(df_b.index, index=df_b['business_id']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Due to categories, mabe there is no need of similarity there, as i can just choose same category. I could use similarity to review text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendation function !!! need changes!!\n",
    "def recommend(title, cosine_sim=cosine_sim):\n",
    "\n",
    "    # Get the index of the movie that matches the title\n",
    "    idx = indices[title]\n",
    "    # Get the pairwise similarity scores of all movies with the given movie\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    # Get the scores of the 15 most similar movies\n",
    "    sim_scores = sim_scores[1:16]\n",
    "    # Get the movie indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    # Remove low-rated movies or outliers\n",
    "    for i in movie_indices:\n",
    "        pop = meta.at[i,'vote_average']\n",
    "        if pop<5 or pop>10:\n",
    "            movie_indices.remove(i)\n",
    "\n",
    "    # Return the most similar movies qualifying the 5.0 rating threshold\n",
    "    return meta[['original_title','vote_average']].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import KFold\n",
    "from surprise.model_selection.validation import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader() # Used to parse a file containing ratings\n",
    "df2 = Dataset.load_from_df(df[['user_id', 'business_id', 'review_stars']], reader)\n",
    "kf = KFold(n_splits=5)\n",
    "kf.split(df2) # Split the data into folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Single Value Decomposition (SVD) for cross-validation and fitting\n",
    "svd = SVD()\n",
    "cross_validate(svd, df2, measures=['RMSE', 'MAE'])\n",
    "\n",
    "trainset = df2.build_full_trainset()\n",
    "svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO\n",
    "### use check-in to find the most visited places\n",
    "### Use catogories to break data !!!!(Done with categorize func)\n",
    "### Remove bussineses with categories out of interest for example guns\n",
    "### Need to find a way to take advantage of review text (sure the is need of Vectorizer)\n",
    "### I could find corellation between categories: for example food vs restaurant\n",
    "### Efficient way for cosine similarity, one way is to use some keywords and then return only results with cosine similarity >0. In this way i will get all the bussiness_ids coresponding to my keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
